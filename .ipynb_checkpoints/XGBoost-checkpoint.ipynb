{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MatthewBarnette/final_project_2/.direnv/python-3.5.0/lib/python3.5/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "%matplotlib inline\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing I need to do is import the libraries I will use. The ones I use most are pandas and XGBoost. Pandas reads in the files and converts them into a dataframe, while XGBoost is what I use to write my predictions program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('SF_crime/test.csv', index_col='Id')\n",
    "test = test.rename(columns={'X': 'Longitude', \"Y\": \"Latitude\"})\n",
    "test.Dates = pd.to_datetime(test.Dates)\n",
    "test_keep = test\n",
    "crime_in_sf = pd.read_csv('SF_crime/train.csv')\n",
    "crime_in_sf.Dates = pd.to_datetime(crime_in_sf.Dates)\n",
    "crime_in_sf = crime_in_sf.rename(columns={'X': 'Longitude', \"Y\": \"Latitude\",})\n",
    "crime_in_sf = crime_in_sf.drop(['Resolution', 'Descript'], axis=1)\n",
    "crime_train, crime_test = train_test_split(crime_in_sf, test_size=.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing I have to do is read in all the files and make any corrections to them so I can make them more readable. I change some column names (X and Y) so that they are easier to read and convert the Dates column to a datetime format so I can pull out individual years or days if I need too. I also drop two columns off of the training data as they don't influence my predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MatthewBarnette/final_project_2/.direnv/python-3.5.0/lib/python3.5/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/MatthewBarnette/final_project_2/.direnv/python-3.5.0/lib/python3.5/site-packages/ipykernel/__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "for column in test.columns.values:\n",
    "    if column != 'Longitude' and column != 'Latitude':\n",
    "        le.fit(test[column])\n",
    "        test[column] = le.transform(test[column])\n",
    "\n",
    "for column in crime_in_sf.columns.values:\n",
    "    if column != 'Longitude' and column != 'Latitude':\n",
    "        le.fit(crime_in_sf[column])\n",
    "        crime_train[column] = le.transform(crime_train[column])\n",
    "\n",
    "for column in crime_in_sf.columns.values:\n",
    "    if column != 'Longitude' and column != 'Latitude':\n",
    "        le.fit(crime_in_sf[column])        \n",
    "        crime_test[column] = le.transform(crime_test[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I take the information, except for the latitude and longitude, and convert it from strings into integers. Each one is in a dictionary and stored so that they can be converted back later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categories = crime_train.Category\n",
    "crime_train = crime_train.drop('Category', axis=1)\n",
    "\n",
    "categories2 = crime_test.Category\n",
    "crime_test = crime_test.drop('Category', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To properly train my data I needed to make the categories of crimes seperate from the rest of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(crime_train.as_matrix(),\n",
    "                     label=categories)\n",
    "dtest = xgb.DMatrix(crime_test.as_matrix(),\n",
    "                    label=categories2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is separated it needs to be prepared to be put into the decision tree. The first thing that needs to happen is that the information is converted from a pandas table into a matrix, and the categories need to be added in their own identifier so that the program knows what it's predicting on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param = {'bst:max_depth':6, 'objective':'multi:softprob', 'num_class':39}\n",
    "param['nthread'] = 4\n",
    "param['eval_metric'] = ['merror', 'mlogloss']\n",
    "evallist  = [(dtest,'eval'), (dtrain,'train')]\n",
    "num_round = 280"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly I need to tell the program how it's suppose to wrong and what it should use to evaluate the information. I set how large of a tree I want (the max_depth), what I want it to return (softprob), how many categories it should be in. \n",
    "I also set up the evaluation metrics that it would run on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until train error hasn't decreased in 3 rounds.\n",
      "Multiple eval metrics have been passed: 'mlogloss' will be used for early stopping.\n",
      "\n",
      "[0]\teval-merror:0.744966\teval-mlogloss:3.105221\ttrain-merror:0.742843\ttrain-mlogloss:3.100287\n",
      "[1]\teval-merror:0.738694\teval-mlogloss:2.925017\ttrain-merror:0.735478\ttrain-mlogloss:2.917377\n",
      "[2]\teval-merror:0.736570\teval-mlogloss:2.810193\ttrain-merror:0.733469\ttrain-mlogloss:2.800245\n",
      "[3]\teval-merror:0.735263\teval-mlogloss:2.727604\ttrain-merror:0.731953\ttrain-mlogloss:2.715515\n",
      "[4]\teval-merror:0.734093\teval-mlogloss:2.666842\ttrain-merror:0.730406\ttrain-mlogloss:2.652890\n",
      "[5]\teval-merror:0.733153\teval-mlogloss:2.619537\ttrain-merror:0.729493\ttrain-mlogloss:2.603561\n",
      "[6]\teval-merror:0.732381\teval-mlogloss:2.582603\ttrain-merror:0.728652\ttrain-mlogloss:2.564752\n",
      "[7]\teval-merror:0.731789\teval-mlogloss:2.553843\ttrain-merror:0.728033\ttrain-mlogloss:2.533941\n",
      "[8]\teval-merror:0.730867\teval-mlogloss:2.530344\ttrain-merror:0.726955\ttrain-mlogloss:2.508746\n",
      "[9]\teval-merror:0.730377\teval-mlogloss:2.511313\ttrain-merror:0.726344\ttrain-mlogloss:2.487900\n",
      "[10]\teval-merror:0.729531\teval-mlogloss:2.495221\ttrain-merror:0.725416\ttrain-mlogloss:2.470002\n",
      "[11]\teval-merror:0.729110\teval-mlogloss:2.482169\ttrain-merror:0.724884\ttrain-mlogloss:2.455163\n",
      "[12]\teval-merror:0.728674\teval-mlogloss:2.471274\ttrain-merror:0.724330\ttrain-mlogloss:2.442533\n",
      "[13]\teval-merror:0.728182\teval-mlogloss:2.461987\ttrain-merror:0.723778\ttrain-mlogloss:2.431184\n",
      "[14]\teval-merror:0.728034\teval-mlogloss:2.454681\ttrain-merror:0.723371\ttrain-mlogloss:2.422100\n",
      "[15]\teval-merror:0.727795\teval-mlogloss:2.448067\ttrain-merror:0.722770\ttrain-mlogloss:2.413730\n",
      "[16]\teval-merror:0.727521\teval-mlogloss:2.443116\ttrain-merror:0.722418\ttrain-mlogloss:2.406995\n",
      "[17]\teval-merror:0.727145\teval-mlogloss:2.438315\ttrain-merror:0.721796\ttrain-mlogloss:2.400415\n",
      "[18]\teval-merror:0.726915\teval-mlogloss:2.433993\ttrain-merror:0.721213\ttrain-mlogloss:2.394441\n",
      "[19]\teval-merror:0.726536\teval-mlogloss:2.430223\ttrain-merror:0.720424\ttrain-mlogloss:2.389029\n",
      "[20]\teval-merror:0.726143\teval-mlogloss:2.426893\ttrain-merror:0.719972\ttrain-mlogloss:2.383954\n",
      "[21]\teval-merror:0.725719\teval-mlogloss:2.424062\ttrain-merror:0.719364\ttrain-mlogloss:2.379374\n",
      "[22]\teval-merror:0.725514\teval-mlogloss:2.421673\ttrain-merror:0.718863\ttrain-mlogloss:2.375294\n",
      "[23]\teval-merror:0.725315\teval-mlogloss:2.419710\ttrain-merror:0.718436\ttrain-mlogloss:2.371753\n",
      "[24]\teval-merror:0.724956\teval-mlogloss:2.417846\ttrain-merror:0.717924\ttrain-mlogloss:2.368137\n",
      "[25]\teval-merror:0.724700\teval-mlogloss:2.416003\ttrain-merror:0.717396\ttrain-mlogloss:2.364686\n",
      "[26]\teval-merror:0.724426\teval-mlogloss:2.414631\ttrain-merror:0.716942\ttrain-mlogloss:2.361911\n",
      "[27]\teval-merror:0.724284\teval-mlogloss:2.413527\ttrain-merror:0.716532\ttrain-mlogloss:2.359200\n",
      "[28]\teval-merror:0.723871\teval-mlogloss:2.411918\ttrain-merror:0.715910\ttrain-mlogloss:2.355808\n",
      "[29]\teval-merror:0.723854\teval-mlogloss:2.410955\ttrain-merror:0.715634\ttrain-mlogloss:2.353329\n",
      "[30]\teval-merror:0.723592\teval-mlogloss:2.409903\ttrain-merror:0.715135\ttrain-mlogloss:2.350773\n",
      "[31]\teval-merror:0.723492\teval-mlogloss:2.409019\ttrain-merror:0.714788\ttrain-mlogloss:2.348493\n",
      "[32]\teval-merror:0.723165\teval-mlogloss:2.408001\ttrain-merror:0.714387\ttrain-mlogloss:2.346041\n",
      "[33]\teval-merror:0.723045\teval-mlogloss:2.407135\ttrain-merror:0.714061\ttrain-mlogloss:2.343678\n",
      "[34]\teval-merror:0.722735\teval-mlogloss:2.406358\ttrain-merror:0.713693\ttrain-mlogloss:2.341444\n",
      "[35]\teval-merror:0.722547\teval-mlogloss:2.405296\ttrain-merror:0.713129\ttrain-mlogloss:2.338953\n",
      "[36]\teval-merror:0.722348\teval-mlogloss:2.404524\ttrain-merror:0.712673\ttrain-mlogloss:2.336775\n",
      "[37]\teval-merror:0.722029\teval-mlogloss:2.403687\ttrain-merror:0.712248\ttrain-mlogloss:2.334384\n",
      "[38]\teval-merror:0.721753\teval-mlogloss:2.402982\ttrain-merror:0.711789\ttrain-mlogloss:2.332527\n",
      "[39]\teval-merror:0.721519\teval-mlogloss:2.402035\ttrain-merror:0.711436\ttrain-mlogloss:2.330302\n",
      "[40]\teval-merror:0.721314\teval-mlogloss:2.400976\ttrain-merror:0.711020\ttrain-mlogloss:2.327901\n",
      "[41]\teval-merror:0.721143\teval-mlogloss:2.400354\ttrain-merror:0.710602\ttrain-mlogloss:2.325938\n",
      "[42]\teval-merror:0.721180\teval-mlogloss:2.399776\ttrain-merror:0.710170\ttrain-mlogloss:2.323956\n",
      "[43]\teval-merror:0.720845\teval-mlogloss:2.399029\ttrain-merror:0.709724\ttrain-mlogloss:2.321800\n",
      "[44]\teval-merror:0.720605\teval-mlogloss:2.398449\ttrain-merror:0.709319\ttrain-mlogloss:2.320020\n",
      "[45]\teval-merror:0.720543\teval-mlogloss:2.397859\ttrain-merror:0.708911\ttrain-mlogloss:2.318106\n",
      "[46]\teval-merror:0.720469\teval-mlogloss:2.397528\ttrain-merror:0.708748\ttrain-mlogloss:2.316550\n",
      "[47]\teval-merror:0.720318\teval-mlogloss:2.396963\ttrain-merror:0.708387\ttrain-mlogloss:2.314836\n",
      "[48]\teval-merror:0.720212\teval-mlogloss:2.396623\ttrain-merror:0.707903\ttrain-mlogloss:2.313004\n",
      "[49]\teval-merror:0.720019\teval-mlogloss:2.396104\ttrain-merror:0.707679\ttrain-mlogloss:2.311321\n",
      "[50]\teval-merror:0.719885\teval-mlogloss:2.395797\ttrain-merror:0.707402\ttrain-mlogloss:2.309633\n",
      "[51]\teval-merror:0.719837\teval-mlogloss:2.395212\ttrain-merror:0.707053\ttrain-mlogloss:2.307705\n",
      "[52]\teval-merror:0.719854\teval-mlogloss:2.394962\ttrain-merror:0.706793\ttrain-mlogloss:2.306016\n",
      "[53]\teval-merror:0.719845\teval-mlogloss:2.394758\ttrain-merror:0.706614\ttrain-mlogloss:2.304840\n",
      "[54]\teval-merror:0.719546\teval-mlogloss:2.394101\ttrain-merror:0.705979\ttrain-mlogloss:2.303045\n",
      "[55]\teval-merror:0.719535\teval-mlogloss:2.393830\ttrain-merror:0.705823\ttrain-mlogloss:2.301853\n",
      "[56]\teval-merror:0.719427\teval-mlogloss:2.393330\ttrain-merror:0.705495\ttrain-mlogloss:2.300185\n",
      "[57]\teval-merror:0.719392\teval-mlogloss:2.393019\ttrain-merror:0.705318\ttrain-mlogloss:2.298894\n",
      "[58]\teval-merror:0.719358\teval-mlogloss:2.392733\ttrain-merror:0.705111\ttrain-mlogloss:2.297323\n",
      "[59]\teval-merror:0.719353\teval-mlogloss:2.392508\ttrain-merror:0.704881\ttrain-mlogloss:2.295919\n",
      "[60]\teval-merror:0.719213\teval-mlogloss:2.392191\ttrain-merror:0.704627\ttrain-mlogloss:2.294411\n",
      "[61]\teval-merror:0.719093\teval-mlogloss:2.391868\ttrain-merror:0.704284\ttrain-mlogloss:2.292953\n",
      "[62]\teval-merror:0.719017\teval-mlogloss:2.391379\ttrain-merror:0.703948\ttrain-mlogloss:2.291221\n",
      "[63]\teval-merror:0.718792\teval-mlogloss:2.390895\ttrain-merror:0.703669\ttrain-mlogloss:2.289574\n",
      "[64]\teval-merror:0.718604\teval-mlogloss:2.390278\ttrain-merror:0.703245\ttrain-mlogloss:2.287695\n",
      "[65]\teval-merror:0.718444\teval-mlogloss:2.389744\ttrain-merror:0.702847\ttrain-mlogloss:2.285933\n",
      "[66]\teval-merror:0.718385\teval-mlogloss:2.389497\ttrain-merror:0.702621\ttrain-mlogloss:2.284519\n",
      "[67]\teval-merror:0.718088\teval-mlogloss:2.389122\ttrain-merror:0.702177\ttrain-mlogloss:2.282905\n",
      "[68]\teval-merror:0.718029\teval-mlogloss:2.388784\ttrain-merror:0.701808\ttrain-mlogloss:2.281383\n",
      "[69]\teval-merror:0.718134\teval-mlogloss:2.388640\ttrain-merror:0.701579\ttrain-mlogloss:2.280228\n",
      "[70]\teval-merror:0.717863\teval-mlogloss:2.388426\ttrain-merror:0.701188\ttrain-mlogloss:2.278852\n",
      "[71]\teval-merror:0.717735\teval-mlogloss:2.388251\ttrain-merror:0.700983\ttrain-mlogloss:2.277467\n",
      "[72]\teval-merror:0.717604\teval-mlogloss:2.387986\ttrain-merror:0.700715\ttrain-mlogloss:2.275956\n",
      "[73]\teval-merror:0.717471\teval-mlogloss:2.387736\ttrain-merror:0.700453\ttrain-mlogloss:2.274704\n",
      "[74]\teval-merror:0.717456\teval-mlogloss:2.387271\ttrain-merror:0.699975\ttrain-mlogloss:2.273089\n",
      "[75]\teval-merror:0.717459\teval-mlogloss:2.387168\ttrain-merror:0.699791\ttrain-mlogloss:2.272042\n",
      "[76]\teval-merror:0.717368\teval-mlogloss:2.386916\ttrain-merror:0.699464\ttrain-mlogloss:2.270582\n",
      "[77]\teval-merror:0.717300\teval-mlogloss:2.386665\ttrain-merror:0.699185\ttrain-mlogloss:2.269221\n",
      "[78]\teval-merror:0.717163\teval-mlogloss:2.386144\ttrain-merror:0.698859\ttrain-mlogloss:2.267556\n",
      "[79]\teval-merror:0.717100\teval-mlogloss:2.385915\ttrain-merror:0.698540\ttrain-mlogloss:2.266343\n",
      "[80]\teval-merror:0.717058\teval-mlogloss:2.385665\ttrain-merror:0.698270\ttrain-mlogloss:2.265010\n",
      "[81]\teval-merror:0.716895\teval-mlogloss:2.385338\ttrain-merror:0.698046\ttrain-mlogloss:2.263341\n",
      "[82]\teval-merror:0.716727\teval-mlogloss:2.385051\ttrain-merror:0.697718\ttrain-mlogloss:2.261780\n",
      "[83]\teval-merror:0.716602\teval-mlogloss:2.384902\ttrain-merror:0.697545\ttrain-mlogloss:2.260653\n",
      "[84]\teval-merror:0.716537\teval-mlogloss:2.384718\ttrain-merror:0.697259\ttrain-mlogloss:2.259268\n",
      "[85]\teval-merror:0.716369\teval-mlogloss:2.384560\ttrain-merror:0.696951\ttrain-mlogloss:2.257976\n",
      "[86]\teval-merror:0.716275\teval-mlogloss:2.384222\ttrain-merror:0.696733\ttrain-mlogloss:2.256420\n",
      "[87]\teval-merror:0.716255\teval-mlogloss:2.383955\ttrain-merror:0.696524\ttrain-mlogloss:2.254961\n",
      "[88]\teval-merror:0.716226\teval-mlogloss:2.383838\ttrain-merror:0.696311\ttrain-mlogloss:2.253841\n",
      "[89]\teval-merror:0.716232\teval-mlogloss:2.383725\ttrain-merror:0.696123\ttrain-mlogloss:2.252670\n",
      "[90]\teval-merror:0.716192\teval-mlogloss:2.383622\ttrain-merror:0.695825\ttrain-mlogloss:2.251594\n",
      "[91]\teval-merror:0.716104\teval-mlogloss:2.383298\ttrain-merror:0.695417\ttrain-mlogloss:2.250178\n",
      "[92]\teval-merror:0.716010\teval-mlogloss:2.383056\ttrain-merror:0.695004\ttrain-mlogloss:2.248674\n",
      "[93]\teval-merror:0.715868\teval-mlogloss:2.382803\ttrain-merror:0.694624\ttrain-mlogloss:2.247420\n",
      "[94]\teval-merror:0.715788\teval-mlogloss:2.382762\ttrain-merror:0.694413\ttrain-mlogloss:2.246437\n",
      "[95]\teval-merror:0.715617\teval-mlogloss:2.382513\ttrain-merror:0.694201\ttrain-mlogloss:2.245216\n",
      "[96]\teval-merror:0.715645\teval-mlogloss:2.382336\ttrain-merror:0.693910\ttrain-mlogloss:2.243966\n",
      "[97]\teval-merror:0.715489\teval-mlogloss:2.382083\ttrain-merror:0.693553\ttrain-mlogloss:2.242827\n",
      "[98]\teval-merror:0.715418\teval-mlogloss:2.381858\ttrain-merror:0.693284\ttrain-mlogloss:2.241676\n",
      "[99]\teval-merror:0.715412\teval-mlogloss:2.381780\ttrain-merror:0.693058\ttrain-mlogloss:2.240692\n",
      "[100]\teval-merror:0.715406\teval-mlogloss:2.381684\ttrain-merror:0.692823\ttrain-mlogloss:2.239597\n",
      "[101]\teval-merror:0.715312\teval-mlogloss:2.381460\ttrain-merror:0.692378\ttrain-mlogloss:2.238189\n",
      "[102]\teval-merror:0.715253\teval-mlogloss:2.381344\ttrain-merror:0.692078\ttrain-mlogloss:2.237056\n",
      "[103]\teval-merror:0.715233\teval-mlogloss:2.381391\ttrain-merror:0.691828\ttrain-mlogloss:2.236055\n",
      "[104]\teval-merror:0.715176\teval-mlogloss:2.381301\ttrain-merror:0.691644\ttrain-mlogloss:2.234980\n",
      "[105]\teval-merror:0.715110\teval-mlogloss:2.381200\ttrain-merror:0.691355\ttrain-mlogloss:2.233762\n",
      "[106]\teval-merror:0.715116\teval-mlogloss:2.381109\ttrain-merror:0.691145\ttrain-mlogloss:2.232554\n",
      "[107]\teval-merror:0.715065\teval-mlogloss:2.380953\ttrain-merror:0.690888\ttrain-mlogloss:2.231351\n",
      "[108]\teval-merror:0.715065\teval-mlogloss:2.380631\ttrain-merror:0.690448\ttrain-mlogloss:2.229914\n",
      "[109]\teval-merror:0.714988\teval-mlogloss:2.380443\ttrain-merror:0.690167\ttrain-mlogloss:2.228552\n",
      "[110]\teval-merror:0.714976\teval-mlogloss:2.380386\ttrain-merror:0.689983\ttrain-mlogloss:2.227562\n",
      "[111]\teval-merror:0.714897\teval-mlogloss:2.380333\ttrain-merror:0.689782\ttrain-mlogloss:2.226526\n",
      "[112]\teval-merror:0.714806\teval-mlogloss:2.380155\ttrain-merror:0.689480\ttrain-mlogloss:2.225321\n",
      "[113]\teval-merror:0.714800\teval-mlogloss:2.380014\ttrain-merror:0.689267\ttrain-mlogloss:2.224127\n",
      "[114]\teval-merror:0.714771\teval-mlogloss:2.379956\ttrain-merror:0.689083\ttrain-mlogloss:2.223038\n",
      "[115]\teval-merror:0.714620\teval-mlogloss:2.379692\ttrain-merror:0.688831\ttrain-mlogloss:2.221798\n",
      "[116]\teval-merror:0.714564\teval-mlogloss:2.379557\ttrain-merror:0.688510\ttrain-mlogloss:2.220692\n",
      "[117]\teval-merror:0.714521\teval-mlogloss:2.379459\ttrain-merror:0.688333\ttrain-mlogloss:2.219573\n",
      "[118]\teval-merror:0.714427\teval-mlogloss:2.379301\ttrain-merror:0.688085\ttrain-mlogloss:2.218442\n",
      "[119]\teval-merror:0.714435\teval-mlogloss:2.379165\ttrain-merror:0.687785\ttrain-mlogloss:2.217314\n",
      "[120]\teval-merror:0.714427\teval-mlogloss:2.379127\ttrain-merror:0.687519\ttrain-mlogloss:2.216389\n",
      "[121]\teval-merror:0.714341\teval-mlogloss:2.378942\ttrain-merror:0.687358\ttrain-mlogloss:2.215164\n",
      "[122]\teval-merror:0.714341\teval-mlogloss:2.378762\ttrain-merror:0.687200\ttrain-mlogloss:2.213911\n",
      "[123]\teval-merror:0.714324\teval-mlogloss:2.378670\ttrain-merror:0.686908\ttrain-mlogloss:2.212786\n",
      "[124]\teval-merror:0.714159\teval-mlogloss:2.378413\ttrain-merror:0.686595\ttrain-mlogloss:2.211513\n",
      "[125]\teval-merror:0.714082\teval-mlogloss:2.378287\ttrain-merror:0.686342\ttrain-mlogloss:2.210487\n",
      "[126]\teval-merror:0.714025\teval-mlogloss:2.378229\ttrain-merror:0.686171\ttrain-mlogloss:2.209574\n",
      "[127]\teval-merror:0.714077\teval-mlogloss:2.378139\ttrain-merror:0.685934\ttrain-mlogloss:2.208489\n",
      "[128]\teval-merror:0.714071\teval-mlogloss:2.378068\ttrain-merror:0.685778\ttrain-mlogloss:2.207495\n",
      "[129]\teval-merror:0.714011\teval-mlogloss:2.378006\ttrain-merror:0.685429\ttrain-mlogloss:2.206459\n",
      "[130]\teval-merror:0.714028\teval-mlogloss:2.377999\ttrain-merror:0.685209\ttrain-mlogloss:2.205540\n",
      "[131]\teval-merror:0.714040\teval-mlogloss:2.377822\ttrain-merror:0.684883\ttrain-mlogloss:2.204350\n",
      "[132]\teval-merror:0.713971\teval-mlogloss:2.377786\ttrain-merror:0.684668\ttrain-mlogloss:2.203307\n",
      "[133]\teval-merror:0.713974\teval-mlogloss:2.377663\ttrain-merror:0.684402\ttrain-mlogloss:2.202228\n",
      "[134]\teval-merror:0.713889\teval-mlogloss:2.377506\ttrain-merror:0.684178\ttrain-mlogloss:2.201319\n",
      "[135]\teval-merror:0.713772\teval-mlogloss:2.377233\ttrain-merror:0.683873\ttrain-mlogloss:2.200023\n",
      "[136]\teval-merror:0.713667\teval-mlogloss:2.377147\ttrain-merror:0.683632\ttrain-mlogloss:2.198867\n",
      "[137]\teval-merror:0.713587\teval-mlogloss:2.377009\ttrain-merror:0.683262\ttrain-mlogloss:2.197860\n",
      "[138]\teval-merror:0.713499\teval-mlogloss:2.376940\ttrain-merror:0.683022\ttrain-mlogloss:2.196794\n",
      "[139]\teval-merror:0.713422\teval-mlogloss:2.376856\ttrain-merror:0.682848\ttrain-mlogloss:2.195866\n",
      "[140]\teval-merror:0.713351\teval-mlogloss:2.376789\ttrain-merror:0.682459\ttrain-mlogloss:2.194813\n",
      "[141]\teval-merror:0.713245\teval-mlogloss:2.376760\ttrain-merror:0.682219\ttrain-mlogloss:2.193800\n",
      "[142]\teval-merror:0.713291\teval-mlogloss:2.376730\ttrain-merror:0.682007\ttrain-mlogloss:2.192849\n",
      "[143]\teval-merror:0.713234\teval-mlogloss:2.376545\ttrain-merror:0.681768\ttrain-mlogloss:2.191735\n",
      "[144]\teval-merror:0.713274\teval-mlogloss:2.376455\ttrain-merror:0.681563\ttrain-mlogloss:2.190850\n",
      "[145]\teval-merror:0.713285\teval-mlogloss:2.376339\ttrain-merror:0.681341\ttrain-mlogloss:2.189896\n",
      "[146]\teval-merror:0.713254\teval-mlogloss:2.376183\ttrain-merror:0.681153\ttrain-mlogloss:2.188947\n",
      "[147]\teval-merror:0.713225\teval-mlogloss:2.376102\ttrain-merror:0.680938\ttrain-mlogloss:2.187930\n",
      "[148]\teval-merror:0.713208\teval-mlogloss:2.376047\ttrain-merror:0.680699\ttrain-mlogloss:2.186976\n",
      "[149]\teval-merror:0.713160\teval-mlogloss:2.376029\ttrain-merror:0.680475\ttrain-mlogloss:2.186263\n",
      "[150]\teval-merror:0.713163\teval-mlogloss:2.375921\ttrain-merror:0.680221\ttrain-mlogloss:2.185069\n",
      "[151]\teval-merror:0.713151\teval-mlogloss:2.375929\ttrain-merror:0.680031\ttrain-mlogloss:2.184104\n",
      "[152]\teval-merror:0.713094\teval-mlogloss:2.375870\ttrain-merror:0.679740\ttrain-mlogloss:2.183031\n",
      "[153]\teval-merror:0.713094\teval-mlogloss:2.375810\ttrain-merror:0.679516\ttrain-mlogloss:2.181936\n",
      "[154]\teval-merror:0.713094\teval-mlogloss:2.375704\ttrain-merror:0.679251\ttrain-mlogloss:2.180796\n",
      "[155]\teval-merror:0.713017\teval-mlogloss:2.375610\ttrain-merror:0.679038\ttrain-mlogloss:2.179781\n",
      "[156]\teval-merror:0.713040\teval-mlogloss:2.375510\ttrain-merror:0.678674\ttrain-mlogloss:2.178572\n",
      "[157]\teval-merror:0.712961\teval-mlogloss:2.375431\ttrain-merror:0.678332\ttrain-mlogloss:2.177518\n",
      "[158]\teval-merror:0.712932\teval-mlogloss:2.375251\ttrain-merror:0.678093\ttrain-mlogloss:2.176543\n",
      "[159]\teval-merror:0.712892\teval-mlogloss:2.375033\ttrain-merror:0.677801\ttrain-mlogloss:2.175346\n",
      "[160]\teval-merror:0.712881\teval-mlogloss:2.374964\ttrain-merror:0.677525\ttrain-mlogloss:2.174400\n",
      "[161]\teval-merror:0.712753\teval-mlogloss:2.374915\ttrain-merror:0.677332\ttrain-mlogloss:2.173544\n",
      "[162]\teval-merror:0.712730\teval-mlogloss:2.374802\ttrain-merror:0.677125\ttrain-mlogloss:2.172654\n",
      "[163]\teval-merror:0.712667\teval-mlogloss:2.374800\ttrain-merror:0.676965\ttrain-mlogloss:2.171845\n",
      "[164]\teval-merror:0.712699\teval-mlogloss:2.374692\ttrain-merror:0.676738\ttrain-mlogloss:2.170785\n",
      "[165]\teval-merror:0.712673\teval-mlogloss:2.374662\ttrain-merror:0.676527\ttrain-mlogloss:2.169800\n",
      "[166]\teval-merror:0.712687\teval-mlogloss:2.374651\ttrain-merror:0.676282\ttrain-mlogloss:2.168825\n",
      "[167]\teval-merror:0.712630\teval-mlogloss:2.374468\ttrain-merror:0.675883\ttrain-mlogloss:2.167663\n",
      "[168]\teval-merror:0.712593\teval-mlogloss:2.374467\ttrain-merror:0.675599\ttrain-mlogloss:2.166800\n",
      "[169]\teval-merror:0.712533\teval-mlogloss:2.374376\ttrain-merror:0.675297\ttrain-mlogloss:2.165703\n",
      "[170]\teval-merror:0.712448\teval-mlogloss:2.374200\ttrain-merror:0.674944\ttrain-mlogloss:2.164626\n",
      "[171]\teval-merror:0.712442\teval-mlogloss:2.374164\ttrain-merror:0.674741\ttrain-mlogloss:2.163671\n",
      "[172]\teval-merror:0.712451\teval-mlogloss:2.374114\ttrain-merror:0.674479\ttrain-mlogloss:2.162643\n",
      "[173]\teval-merror:0.712488\teval-mlogloss:2.373944\ttrain-merror:0.674080\ttrain-mlogloss:2.161542\n",
      "[174]\teval-merror:0.712451\teval-mlogloss:2.373836\ttrain-merror:0.673974\ttrain-mlogloss:2.160625\n",
      "[175]\teval-merror:0.712448\teval-mlogloss:2.373851\ttrain-merror:0.673771\ttrain-mlogloss:2.159728\n",
      "[176]\teval-merror:0.712394\teval-mlogloss:2.373871\ttrain-merror:0.673551\ttrain-mlogloss:2.158957\n",
      "[177]\teval-merror:0.712380\teval-mlogloss:2.373814\ttrain-merror:0.673351\ttrain-mlogloss:2.158142\n",
      "[178]\teval-merror:0.712300\teval-mlogloss:2.373694\ttrain-merror:0.673203\ttrain-mlogloss:2.157194\n",
      "[179]\teval-merror:0.712223\teval-mlogloss:2.373607\ttrain-merror:0.672960\ttrain-mlogloss:2.156060\n",
      "[180]\teval-merror:0.712269\teval-mlogloss:2.373593\ttrain-merror:0.672769\ttrain-mlogloss:2.155127\n",
      "[181]\teval-merror:0.712132\teval-mlogloss:2.373479\ttrain-merror:0.672535\ttrain-mlogloss:2.154134\n",
      "[182]\teval-merror:0.712112\teval-mlogloss:2.373491\ttrain-merror:0.672376\ttrain-mlogloss:2.153306\n",
      "[183]\teval-merror:0.712104\teval-mlogloss:2.373451\ttrain-merror:0.672188\ttrain-mlogloss:2.152559\n",
      "[184]\teval-merror:0.712010\teval-mlogloss:2.373343\ttrain-merror:0.671905\ttrain-mlogloss:2.151668\n",
      "[185]\teval-merror:0.712027\teval-mlogloss:2.373350\ttrain-merror:0.671704\ttrain-mlogloss:2.150832\n",
      "[186]\teval-merror:0.712004\teval-mlogloss:2.373270\ttrain-merror:0.671423\ttrain-mlogloss:2.149872\n",
      "[187]\teval-merror:0.711995\teval-mlogloss:2.373283\ttrain-merror:0.671174\ttrain-mlogloss:2.149140\n",
      "[188]\teval-merror:0.711973\teval-mlogloss:2.373269\ttrain-merror:0.671034\ttrain-mlogloss:2.148487\n",
      "[189]\teval-merror:0.711950\teval-mlogloss:2.373196\ttrain-merror:0.670770\ttrain-mlogloss:2.147688\n",
      "[190]\teval-merror:0.711893\teval-mlogloss:2.373110\ttrain-merror:0.670540\ttrain-mlogloss:2.146832\n",
      "[191]\teval-merror:0.711881\teval-mlogloss:2.373065\ttrain-merror:0.670403\ttrain-mlogloss:2.145813\n",
      "[192]\teval-merror:0.711836\teval-mlogloss:2.373045\ttrain-merror:0.670179\ttrain-mlogloss:2.145020\n",
      "[193]\teval-merror:0.711705\teval-mlogloss:2.372934\ttrain-merror:0.669882\ttrain-mlogloss:2.144057\n",
      "[194]\teval-merror:0.711631\teval-mlogloss:2.372888\ttrain-merror:0.669699\ttrain-mlogloss:2.143168\n",
      "[195]\teval-merror:0.711477\teval-mlogloss:2.372796\ttrain-merror:0.669479\ttrain-mlogloss:2.142139\n",
      "[196]\teval-merror:0.711423\teval-mlogloss:2.372733\ttrain-merror:0.669145\ttrain-mlogloss:2.141212\n",
      "[197]\teval-merror:0.711400\teval-mlogloss:2.372674\ttrain-merror:0.668868\ttrain-mlogloss:2.140277\n",
      "[198]\teval-merror:0.711332\teval-mlogloss:2.372604\ttrain-merror:0.668598\ttrain-mlogloss:2.139423\n",
      "[199]\teval-merror:0.711309\teval-mlogloss:2.372607\ttrain-merror:0.668424\ttrain-mlogloss:2.138601\n",
      "[200]\teval-merror:0.711298\teval-mlogloss:2.372576\ttrain-merror:0.668281\ttrain-mlogloss:2.137750\n",
      "[201]\teval-merror:0.711306\teval-mlogloss:2.372484\ttrain-merror:0.668042\ttrain-mlogloss:2.136770\n",
      "[202]\teval-merror:0.711207\teval-mlogloss:2.372430\ttrain-merror:0.667830\ttrain-mlogloss:2.135818\n",
      "[203]\teval-merror:0.711170\teval-mlogloss:2.372359\ttrain-merror:0.667617\ttrain-mlogloss:2.134812\n",
      "[204]\teval-merror:0.711141\teval-mlogloss:2.372325\ttrain-merror:0.667380\ttrain-mlogloss:2.133956\n",
      "[205]\teval-merror:0.711144\teval-mlogloss:2.372322\ttrain-merror:0.667196\ttrain-mlogloss:2.133202\n",
      "[206]\teval-merror:0.711053\teval-mlogloss:2.372255\ttrain-merror:0.666953\ttrain-mlogloss:2.132366\n",
      "[207]\teval-merror:0.711073\teval-mlogloss:2.372333\ttrain-merror:0.666786\ttrain-mlogloss:2.131645\n",
      "[208]\teval-merror:0.711070\teval-mlogloss:2.372309\ttrain-merror:0.666550\ttrain-mlogloss:2.130770\n",
      "[209]\teval-merror:0.711039\teval-mlogloss:2.372241\ttrain-merror:0.666321\ttrain-mlogloss:2.129798\n",
      "[210]\teval-merror:0.711084\teval-mlogloss:2.372243\ttrain-merror:0.666057\ttrain-mlogloss:2.128865\n",
      "[211]\teval-merror:0.711050\teval-mlogloss:2.372244\ttrain-merror:0.665745\ttrain-mlogloss:2.128000\n",
      "[212]\teval-merror:0.710990\teval-mlogloss:2.372259\ttrain-merror:0.665518\ttrain-mlogloss:2.127148\n",
      "[213]\teval-merror:0.710996\teval-mlogloss:2.372169\ttrain-merror:0.665269\ttrain-mlogloss:2.126263\n",
      "[214]\teval-merror:0.710916\teval-mlogloss:2.372106\ttrain-merror:0.665020\ttrain-mlogloss:2.125510\n",
      "[215]\teval-merror:0.710876\teval-mlogloss:2.372118\ttrain-merror:0.664808\ttrain-mlogloss:2.124587\n",
      "[216]\teval-merror:0.710834\teval-mlogloss:2.372118\ttrain-merror:0.664681\ttrain-mlogloss:2.123781\n",
      "[217]\teval-merror:0.710802\teval-mlogloss:2.372080\ttrain-merror:0.664415\ttrain-mlogloss:2.122890\n",
      "[218]\teval-merror:0.710688\teval-mlogloss:2.372025\ttrain-merror:0.664235\ttrain-mlogloss:2.121876\n",
      "[219]\teval-merror:0.710765\teval-mlogloss:2.372043\ttrain-merror:0.663980\ttrain-mlogloss:2.121011\n",
      "[220]\teval-merror:0.710814\teval-mlogloss:2.372053\ttrain-merror:0.663640\ttrain-mlogloss:2.120169\n",
      "[221]\teval-merror:0.710700\teval-mlogloss:2.372018\ttrain-merror:0.663369\ttrain-mlogloss:2.119260\n",
      "[222]\teval-merror:0.710671\teval-mlogloss:2.372007\ttrain-merror:0.663209\ttrain-mlogloss:2.118281\n",
      "[223]\teval-merror:0.710671\teval-mlogloss:2.371979\ttrain-merror:0.662877\ttrain-mlogloss:2.117291\n",
      "[224]\teval-merror:0.710634\teval-mlogloss:2.371967\ttrain-merror:0.662574\ttrain-mlogloss:2.116493\n",
      "[225]\teval-merror:0.710569\teval-mlogloss:2.371864\ttrain-merror:0.662384\ttrain-mlogloss:2.115691\n",
      "[226]\teval-merror:0.710398\teval-mlogloss:2.371867\ttrain-merror:0.662084\ttrain-mlogloss:2.114853\n",
      "[227]\teval-merror:0.710452\teval-mlogloss:2.371805\ttrain-merror:0.661788\ttrain-mlogloss:2.114003\n",
      "[228]\teval-merror:0.710344\teval-mlogloss:2.371778\ttrain-merror:0.661518\ttrain-mlogloss:2.113083\n",
      "[229]\teval-merror:0.710310\teval-mlogloss:2.371738\ttrain-merror:0.661283\ttrain-mlogloss:2.112206\n",
      "[230]\teval-merror:0.710310\teval-mlogloss:2.371750\ttrain-merror:0.661178\ttrain-mlogloss:2.111523\n",
      "[231]\teval-merror:0.710298\teval-mlogloss:2.371746\ttrain-merror:0.661027\ttrain-mlogloss:2.110663\n",
      "[232]\teval-merror:0.710261\teval-mlogloss:2.371736\ttrain-merror:0.660748\ttrain-mlogloss:2.109830\n",
      "[233]\teval-merror:0.710267\teval-mlogloss:2.371737\ttrain-merror:0.660488\ttrain-mlogloss:2.109113\n",
      "[234]\teval-merror:0.710227\teval-mlogloss:2.371709\ttrain-merror:0.660305\ttrain-mlogloss:2.108348\n",
      "[235]\teval-merror:0.710264\teval-mlogloss:2.371696\ttrain-merror:0.660070\ttrain-mlogloss:2.107484\n",
      "[236]\teval-merror:0.710173\teval-mlogloss:2.371688\ttrain-merror:0.659867\ttrain-mlogloss:2.106728\n",
      "[237]\teval-merror:0.710113\teval-mlogloss:2.371727\ttrain-merror:0.659687\ttrain-mlogloss:2.105911\n",
      "[238]\teval-merror:0.710173\teval-mlogloss:2.371717\ttrain-merror:0.659483\ttrain-mlogloss:2.105109\n",
      "[239]\teval-merror:0.710108\teval-mlogloss:2.371680\ttrain-merror:0.659269\ttrain-mlogloss:2.104323\n",
      "[240]\teval-merror:0.710059\teval-mlogloss:2.371725\ttrain-merror:0.659085\ttrain-mlogloss:2.103485\n",
      "[241]\teval-merror:0.710025\teval-mlogloss:2.371717\ttrain-merror:0.658870\ttrain-mlogloss:2.102628\n",
      "[242]\teval-merror:0.710011\teval-mlogloss:2.371707\ttrain-merror:0.658567\ttrain-mlogloss:2.101788\n",
      "[243]\teval-merror:0.710056\teval-mlogloss:2.371694\ttrain-merror:0.658390\ttrain-mlogloss:2.101092\n",
      "[244]\teval-merror:0.710039\teval-mlogloss:2.371672\ttrain-merror:0.658124\ttrain-mlogloss:2.100206\n",
      "[245]\teval-merror:0.710019\teval-mlogloss:2.371634\ttrain-merror:0.657912\ttrain-mlogloss:2.099339\n",
      "[246]\teval-merror:0.709997\teval-mlogloss:2.371602\ttrain-merror:0.657623\ttrain-mlogloss:2.098494\n",
      "[247]\teval-merror:0.709974\teval-mlogloss:2.371522\ttrain-merror:0.657352\ttrain-mlogloss:2.097428\n",
      "[248]\teval-merror:0.709977\teval-mlogloss:2.371470\ttrain-merror:0.657137\ttrain-mlogloss:2.096507\n",
      "[249]\teval-merror:0.709923\teval-mlogloss:2.371461\ttrain-merror:0.656955\ttrain-mlogloss:2.095611\n",
      "[250]\teval-merror:0.709905\teval-mlogloss:2.371389\ttrain-merror:0.656801\ttrain-mlogloss:2.094715\n",
      "[251]\teval-merror:0.709914\teval-mlogloss:2.371377\ttrain-merror:0.656598\ttrain-mlogloss:2.093777\n",
      "[252]\teval-merror:0.709831\teval-mlogloss:2.371367\ttrain-merror:0.656342\ttrain-mlogloss:2.092771\n",
      "[253]\teval-merror:0.709849\teval-mlogloss:2.371364\ttrain-merror:0.656203\ttrain-mlogloss:2.092064\n",
      "[254]\teval-merror:0.709843\teval-mlogloss:2.371370\ttrain-merror:0.656017\ttrain-mlogloss:2.091298\n",
      "[255]\teval-merror:0.709789\teval-mlogloss:2.371358\ttrain-merror:0.655765\ttrain-mlogloss:2.090465\n",
      "[256]\teval-merror:0.709777\teval-mlogloss:2.371348\ttrain-merror:0.655531\ttrain-mlogloss:2.089690\n",
      "[257]\teval-merror:0.709698\teval-mlogloss:2.371375\ttrain-merror:0.655387\ttrain-mlogloss:2.088922\n",
      "[258]\teval-merror:0.709646\teval-mlogloss:2.371374\ttrain-merror:0.655148\ttrain-mlogloss:2.088252\n",
      "[259]\teval-merror:0.709695\teval-mlogloss:2.371462\ttrain-merror:0.655063\ttrain-mlogloss:2.087613\n",
      "[260]\teval-merror:0.709652\teval-mlogloss:2.371314\ttrain-merror:0.654757\ttrain-mlogloss:2.086714\n",
      "[261]\teval-merror:0.709572\teval-mlogloss:2.371284\ttrain-merror:0.654577\ttrain-mlogloss:2.085972\n",
      "[262]\teval-merror:0.709558\teval-mlogloss:2.371272\ttrain-merror:0.654425\ttrain-mlogloss:2.085147\n",
      "[263]\teval-merror:0.709601\teval-mlogloss:2.371253\ttrain-merror:0.654298\ttrain-mlogloss:2.084475\n",
      "[264]\teval-merror:0.709621\teval-mlogloss:2.371155\ttrain-merror:0.653931\ttrain-mlogloss:2.083586\n",
      "[265]\teval-merror:0.709601\teval-mlogloss:2.371166\ttrain-merror:0.653800\ttrain-mlogloss:2.082783\n",
      "[266]\teval-merror:0.709595\teval-mlogloss:2.371183\ttrain-merror:0.653614\ttrain-mlogloss:2.082025\n",
      "[267]\teval-merror:0.709581\teval-mlogloss:2.371195\ttrain-merror:0.653444\ttrain-mlogloss:2.081398\n",
      "[268]\teval-merror:0.709564\teval-mlogloss:2.371183\ttrain-merror:0.653267\ttrain-mlogloss:2.080610\n",
      "[269]\teval-merror:0.709478\teval-mlogloss:2.371057\ttrain-merror:0.652948\ttrain-mlogloss:2.079578\n",
      "[270]\teval-merror:0.709478\teval-mlogloss:2.371021\ttrain-merror:0.652658\ttrain-mlogloss:2.078684\n",
      "[271]\teval-merror:0.709487\teval-mlogloss:2.370981\ttrain-merror:0.652475\ttrain-mlogloss:2.077932\n",
      "[272]\teval-merror:0.709413\teval-mlogloss:2.370928\ttrain-merror:0.652276\ttrain-mlogloss:2.077119\n",
      "[273]\teval-merror:0.709353\teval-mlogloss:2.370865\ttrain-merror:0.652039\ttrain-mlogloss:2.076335\n",
      "[274]\teval-merror:0.709356\teval-mlogloss:2.370880\ttrain-merror:0.651893\ttrain-mlogloss:2.075595\n",
      "[275]\teval-merror:0.709333\teval-mlogloss:2.370865\ttrain-merror:0.651650\ttrain-mlogloss:2.074918\n",
      "[276]\teval-merror:0.709310\teval-mlogloss:2.370805\ttrain-merror:0.651302\ttrain-mlogloss:2.074060\n",
      "[277]\teval-merror:0.709313\teval-mlogloss:2.370827\ttrain-merror:0.651141\ttrain-mlogloss:2.073385\n",
      "[278]\teval-merror:0.709305\teval-mlogloss:2.370871\ttrain-merror:0.650932\ttrain-mlogloss:2.072749\n",
      "[279]\teval-merror:0.709302\teval-mlogloss:2.370858\ttrain-merror:0.650809\ttrain-mlogloss:2.072151\n"
     ]
    }
   ],
   "source": [
    "bst = xgb.train(param, dtrain, num_round, evallist, early_stopping_rounds=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is where the program trains. As you can see the numbers are getting smaller as they go along, showing that it is getting more accurate. This will hopefully give me a better prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = bst.predict(xgb.DMatrix(test.as_matrix()), output_margin=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is trained I convert the data I will actually predict upon into a matrix and run it through the model I just created and it returns it's predictions based off of all the descisions it had to make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then put those predictions back into a DataFrame. I can easily use that to look over my data and see what it looks like. This is a good time to see if there are any trends or problems that may arise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "le.fit(crime_in_sf.Category)\n",
    "predictions.columns = le.inverse_transform(predictions.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also relabel the information so that it has what the crimes are as opposed to simply numbers from 0-38 so that I know what the crimes that it is predicting on are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Address</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>392172</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6407</td>\n",
       "      <td>-122.399588</td>\n",
       "      <td>37.735051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>392171</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9744</td>\n",
       "      <td>-122.391523</td>\n",
       "      <td>37.732432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>392170</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6336</td>\n",
       "      <td>-122.426002</td>\n",
       "      <td>37.792212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>392169</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10633</td>\n",
       "      <td>-122.437394</td>\n",
       "      <td>37.721412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>392169</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10633</td>\n",
       "      <td>-122.437394</td>\n",
       "      <td>37.721412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dates  DayOfWeek  PdDistrict  Address   Longitude   Latitude\n",
       "Id                                                               \n",
       "0   392172          3           0     6407 -122.399588  37.735051\n",
       "1   392171          3           0     9744 -122.391523  37.732432\n",
       "2   392170          3           4     6336 -122.426002  37.792212\n",
       "3   392169          3           2    10633 -122.437394  37.721412\n",
       "4   392169          3           2    10633 -122.437394  37.721412"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_keep.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what my data looked like when I fed it into my program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARSON</th>\n",
       "      <th>ASSAULT</th>\n",
       "      <th>BAD CHECKS</th>\n",
       "      <th>BRIBERY</th>\n",
       "      <th>BURGLARY</th>\n",
       "      <th>DISORDERLY CONDUCT</th>\n",
       "      <th>DRIVING UNDER THE INFLUENCE</th>\n",
       "      <th>DRUG/NARCOTIC</th>\n",
       "      <th>DRUNKENNESS</th>\n",
       "      <th>EMBEZZLEMENT</th>\n",
       "      <th>...</th>\n",
       "      <th>SEX OFFENSES NON FORCIBLE</th>\n",
       "      <th>STOLEN PROPERTY</th>\n",
       "      <th>SUICIDE</th>\n",
       "      <th>SUSPICIOUS OCC</th>\n",
       "      <th>TREA</th>\n",
       "      <th>TRESPASS</th>\n",
       "      <th>VANDALISM</th>\n",
       "      <th>VEHICLE THEFT</th>\n",
       "      <th>WARRANTS</th>\n",
       "      <th>WEAPON LAWS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000949</td>\n",
       "      <td>0.044045</td>\n",
       "      <td>9.550180e-07</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.003899</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>...</td>\n",
       "      <td>7.601371e-07</td>\n",
       "      <td>0.120559</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.003106</td>\n",
       "      <td>5.250954e-07</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.090599</td>\n",
       "      <td>0.033588</td>\n",
       "      <td>0.003451</td>\n",
       "      <td>0.030885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.034285</td>\n",
       "      <td>1.139519e-06</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>0.002334</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>...</td>\n",
       "      <td>9.537289e-07</td>\n",
       "      <td>0.010991</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.002438</td>\n",
       "      <td>2.473992e-06</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.037942</td>\n",
       "      <td>0.019777</td>\n",
       "      <td>0.012543</td>\n",
       "      <td>0.038404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.006864</td>\n",
       "      <td>3.679608e-06</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.016094</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.003035</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>...</td>\n",
       "      <td>1.185420e-05</td>\n",
       "      <td>0.001401</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>1.301531e-06</td>\n",
       "      <td>0.007248</td>\n",
       "      <td>0.212529</td>\n",
       "      <td>0.324179</td>\n",
       "      <td>0.007601</td>\n",
       "      <td>0.030309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.042451</td>\n",
       "      <td>3.707393e-05</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.059745</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.006270</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>...</td>\n",
       "      <td>5.848924e-05</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.005660</td>\n",
       "      <td>3.670072e-07</td>\n",
       "      <td>0.001865</td>\n",
       "      <td>0.235017</td>\n",
       "      <td>0.117005</td>\n",
       "      <td>0.065951</td>\n",
       "      <td>0.073283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.042451</td>\n",
       "      <td>3.707393e-05</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.059745</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.006270</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>...</td>\n",
       "      <td>5.848924e-05</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.005660</td>\n",
       "      <td>3.670072e-07</td>\n",
       "      <td>0.001865</td>\n",
       "      <td>0.235017</td>\n",
       "      <td>0.117005</td>\n",
       "      <td>0.065951</td>\n",
       "      <td>0.073283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ARSON   ASSAULT    BAD CHECKS   BRIBERY  BURGLARY  DISORDERLY CONDUCT  \\\n",
       "0  0.000949  0.044045  9.550180e-07  0.000110  0.003899            0.000366   \n",
       "1  0.000141  0.034285  1.139519e-06  0.000018  0.000160            0.000917   \n",
       "2  0.000422  0.006864  3.679608e-06  0.000037  0.016094            0.000242   \n",
       "3  0.000037  0.042451  3.707393e-05  0.000398  0.059745            0.001464   \n",
       "4  0.000037  0.042451  3.707393e-05  0.000398  0.059745            0.001464   \n",
       "\n",
       "   DRIVING UNDER THE INFLUENCE  DRUG/NARCOTIC  DRUNKENNESS  EMBEZZLEMENT  \\\n",
       "0                     0.000630       0.000660     0.000150      0.000219   \n",
       "1                     0.001422       0.002334     0.000250      0.000046   \n",
       "2                     0.000045       0.003035     0.001438      0.000054   \n",
       "3                     0.000672       0.006270     0.002349      0.000006   \n",
       "4                     0.000672       0.006270     0.002349      0.000006   \n",
       "\n",
       "      ...       SEX OFFENSES NON FORCIBLE  STOLEN PROPERTY   SUICIDE  \\\n",
       "0     ...                    7.601371e-07         0.120559  0.000072   \n",
       "1     ...                    9.537289e-07         0.010991  0.000019   \n",
       "2     ...                    1.185420e-05         0.001401  0.000169   \n",
       "3     ...                    5.848924e-05         0.001301  0.000006   \n",
       "4     ...                    5.848924e-05         0.001301  0.000006   \n",
       "\n",
       "   SUSPICIOUS OCC          TREA  TRESPASS  VANDALISM  VEHICLE THEFT  WARRANTS  \\\n",
       "0        0.003106  5.250954e-07  0.000603   0.090599       0.033588  0.003451   \n",
       "1        0.002438  2.473992e-06  0.000278   0.037942       0.019777  0.012543   \n",
       "2        0.001423  1.301531e-06  0.007248   0.212529       0.324179  0.007601   \n",
       "3        0.005660  3.670072e-07  0.001865   0.235017       0.117005  0.065951   \n",
       "4        0.005660  3.670072e-07  0.001865   0.235017       0.117005  0.065951   \n",
       "\n",
       "   WEAPON LAWS  \n",
       "0     0.030885  \n",
       "1     0.038404  \n",
       "2     0.030309  \n",
       "3     0.073283  \n",
       "4     0.073283  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is what my predictions look like. Several categories which numbers to identify them and a probabilities of their likelyhood for each type of crime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions['Id'] = predictions.index\n",
    "\n",
    "def order(frame,var):\n",
    "    varlist =[w for w in frame.columns if w not in var]\n",
    "    frame = frame[var+varlist]\n",
    "    return frame\n",
    "\n",
    "predictions = order(predictions,['Id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used a small definition here to add an ID column and put it on the front of my data so that it could be easily identified for the competition, and then I simply run the panel below and create a file which I can submit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions.to_csv('/Users/MatthewBarnette/final_project_predictions//predictions_XGB_280.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
